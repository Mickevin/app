{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "873d0d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Max\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-08 18:04:43.766343: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-03-08 18:04:43.766469: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__' (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [08/Mar/2022 18:04:47] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2022 18:04:47] \"\u001b[36mGET /static/css/bootstrap.min.css HTTP/1.1\u001b[0m\" 304 -\n",
      "127.0.0.1 - - [08/Mar/2022 18:04:47] \"\u001b[36mGET /static/css/jumbotron-narrow.css HTTP/1.1\u001b[0m\" 304 -\n",
      "2022-03-08 18:04:51.347660: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-03-08 18:04:51.415225: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "127.0.0.1 - - [08/Mar/2022 18:04:52] \"POST /predict/ HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2022 18:04:52] \"\u001b[36mGET /static/css/bootstrap.min.css HTTP/1.1\u001b[0m\" 304 -\n",
      "127.0.0.1 - - [08/Mar/2022 18:04:52] \"\u001b[36mGET /static/css/jumbotron-narrow.css HTTP/1.1\u001b[0m\" 304 -\n",
      "127.0.0.1 - - [08/Mar/2022 18:04:52] \"GET /static/origine.png HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [08/Mar/2022 18:04:52] \"GET /static/pred.png HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "# Sauvegarde du fichier data dans l'espace de stockage Azure\n",
    "from flask import Flask, render_template, request\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from azureml.core import Workspace\n",
    "from azureml.core.model import Model\n",
    "\n",
    "from matplotlib.pyplot import imsave\n",
    "from PIL import Image\n",
    "from numpy import array\n",
    "import requests\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Connection à l'espace de travail d'Azure\n",
    "ws = Workspace(subscription_id=\"d5bb9744-4790-446f-b7e1-591e22995cc7\",\n",
    "           resource_group=\"OpenClassrooms\",\n",
    "           workspace_name=\"OC_IA\")\n",
    "model = load_model(Model.get_model_path('Model_vgg_unet', _workspace=ws))\n",
    "\n",
    "def load_img_from_azure(name):\n",
    "    # Connection à l'espace de travail d'Azure\n",
    "    url = f'https://ocia0932039034.blob.core.windows.net/azureml-blobstore-f8554f92-a33d-430c-a1ff-4d9a166c55fc/UI/data/{name}_leftImg8bit.png'\n",
    "    X =  array(Image.open(requests.get(url, stream=True).raw))\n",
    "    imsave('./static/origine.png',X)\n",
    "    return X\n",
    "\n",
    "@app.route('/', methods=['GET'])\n",
    "def california_index():\n",
    "    return render_template(\"index.html\")\n",
    "\n",
    "\n",
    "@app.route('/predict/', methods=['POST'])\n",
    "def result():    \n",
    "    if request.method == 'POST':\n",
    "        name_img = request.form['name_img']\n",
    "        X = array([load_img_from_azure(name_img)])\n",
    "        y = array([[i.argmax() for i in u] for u in model.predict(X[:])])\n",
    "        imsave('./static/pred.png',y.reshape((512,1024)))\n",
    "    return render_template(\"prediction.html\", name_img=name_img)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
